{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Projeto Integrador ADS Fatec \u00b6 Projeto Integrador ADS Fatec - S\u00e3o Jos\u00e9 dos Campos proposto pela empresa Visiona para a identifica\u00e7\u00e3o de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade com caracter\u00edsticas em comum). Projeto Oficial Github ; Sprints e Evolu\u00e7\u00e3o do C\u00f3digo Fonte do Projeto ; Componentes \u00b6 Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Solu\u00e7\u00e3o \u00b6 Desenvolver um Sistema inteligente para a identifica\u00e7\u00e3o autom\u00e1tica de Talh\u00f5es com uso de Intelig\u00eancia Artificial e processos de classifica\u00e7\u00e3o de imagens e com um projeto Web Gis - Sistema de informa\u00e7\u00e3o Geogr\u00e1fico - contendo uma interface gr\u00e1fica agrad\u00e1vel ao usu\u00e1rio e de f\u00e1cil utiliza\u00e7\u00e3o e intuitiva, com uma \u00e1rea de visualiza\u00e7\u00e3o de imagens do mapa, conforme a regi\u00e3o e o per\u00edodo de tempo selecionados pelo usu\u00e1rio, permitindo a manipula\u00e7\u00e3o da imagem (aumentar ou diminuir e demarca\u00e7\u00e3o) e permitir o download desse arquivo para armazenamento. Integrantes do Grupo \u00b6 T\u00e1bata Gl\u00f3ria (Scrum Master - SM) Jo\u00e2o de Freitas (Project Owner - PO) Guilherme Gomes (Back end Developer - DEV) Jo\u00e3o Arruda (Front end Developer - DEV) Abner Ern\u00e2ni dos Anjos (Full Stack Developer - DEV) Implementa\u00e7\u00e3o \u00b6 Como implementar? Tecnologias. Plataformas. Ferramentas. Para a implementa\u00e7\u00e3o ser\u00e1 necess\u00e1rio a utiliza\u00e7\u00e3o das seguintes tecnologias: Landsat-8 API: sat\u00e9lite de observa\u00e7\u00e3o da Terra, esses dados das imagens podem ser usados facilmente com qualquer software que reconhe\u00e7a arquivos GeoTIFF atrav\u00e9s de um arquivo CSV de \u00edndice dos dados do Landsat. Sentinel-2 API: constela\u00e7\u00e3o de dois sat\u00e9lites de observa\u00e7\u00e3o da Terra SEUS Os dados s\u00e3o ideais para aplicativos de agricultura, silvicultura e outros tipos de administra\u00e7\u00e3o de terra. esse conjunto de dados est\u00e1 dispon\u00edvel gratuitamente no programa Google Public Cloud Data. Geo Server: servidor de c\u00f3digo aberto escrito em Java que permite aos usu\u00e1rios compartilhar, processar e editar dados geoespaciais. Projetado para interoperabilidade, publica dados de qualquer fonte de dados espaciais importantes usando padr\u00f5es abertos. PostgreSQL: sistema de gerenciamento de banco de dados objeto-relacional (SGBDOR) baseado no POSTGRES Vers\u00e3o 4.2. Spring Boot: facilitar o processo de configura\u00e7\u00e3o e publica\u00e7\u00e3o de aplica\u00e7\u00f5es. Pode-se escolher os m\u00f3dulos que precisa atrav\u00e9s dos starters que inclui no pom.xml do projeto. Basicamente, s\u00e3o depend\u00eancias que agrupam outras depend\u00eancias. Angular: estrutura de design de aplicativo e plataforma de desenvolvimento para criar aplicativos de p\u00e1gina \u00fanica eficientes e sofisticados. Java: linguagem de programa\u00e7\u00e3o orientada a objetos que \u00e9 amplamente usada para o desenvolvimento de sites e aplicativos. Permite o desenvolvimento de programas multiplataforma, que podem ser executados em qualquer dispositivo. Python: linguagem de programa\u00e7\u00e3o de alto n\u00edvel, interpretada, de script, imperativa, orientada a objetos, funcional, de tipagem din\u00e2mica e forte, para a implementa\u00e7\u00e3o da inteligencia artificial. Conda Environment: gerenciador de ambientes virtuais para a linguagem python. Mkdocs: gerador de documenta\u00e7\u00e3o baseado na linguagem python. Github: Sistema de controle de vers\u00e3o distribuido e gerenciamento de c\u00f3digo-fonte, fornece controle de acesso e v\u00e1rios recursos de colabora\u00e7\u00e3o, como rastreamento de erros, solicita\u00e7\u00f5es de recursos, gerenciamento de tarefas e wikis para cada projeto. Microsoft TEAM: Trata-se de um aplicativo de bate-papo em grupo que permite o gerenciamento de diversas conversas em um \u00fanico ambiente de controle. Foi desenvolvido para facilitar a comunica\u00e7\u00e3o e promover a colabora\u00e7\u00e3o entre as equipes da empresa/projeto.","title":"Home"},{"location":"#projeto-integrador-ads-fatec","text":"Projeto Integrador ADS Fatec - S\u00e3o Jos\u00e9 dos Campos proposto pela empresa Visiona para a identifica\u00e7\u00e3o de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade com caracter\u00edsticas em comum). Projeto Oficial Github ; Sprints e Evolu\u00e7\u00e3o do C\u00f3digo Fonte do Projeto ;","title":"Projeto Integrador ADS Fatec"},{"location":"#componentes","text":"Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final;","title":"Componentes"},{"location":"#solucao","text":"Desenvolver um Sistema inteligente para a identifica\u00e7\u00e3o autom\u00e1tica de Talh\u00f5es com uso de Intelig\u00eancia Artificial e processos de classifica\u00e7\u00e3o de imagens e com um projeto Web Gis - Sistema de informa\u00e7\u00e3o Geogr\u00e1fico - contendo uma interface gr\u00e1fica agrad\u00e1vel ao usu\u00e1rio e de f\u00e1cil utiliza\u00e7\u00e3o e intuitiva, com uma \u00e1rea de visualiza\u00e7\u00e3o de imagens do mapa, conforme a regi\u00e3o e o per\u00edodo de tempo selecionados pelo usu\u00e1rio, permitindo a manipula\u00e7\u00e3o da imagem (aumentar ou diminuir e demarca\u00e7\u00e3o) e permitir o download desse arquivo para armazenamento.","title":"Solu\u00e7\u00e3o"},{"location":"#integrantes-do-grupo","text":"T\u00e1bata Gl\u00f3ria (Scrum Master - SM) Jo\u00e2o de Freitas (Project Owner - PO) Guilherme Gomes (Back end Developer - DEV) Jo\u00e3o Arruda (Front end Developer - DEV) Abner Ern\u00e2ni dos Anjos (Full Stack Developer - DEV)","title":"Integrantes do Grupo"},{"location":"#implementacao","text":"Como implementar? Tecnologias. Plataformas. Ferramentas. Para a implementa\u00e7\u00e3o ser\u00e1 necess\u00e1rio a utiliza\u00e7\u00e3o das seguintes tecnologias: Landsat-8 API: sat\u00e9lite de observa\u00e7\u00e3o da Terra, esses dados das imagens podem ser usados facilmente com qualquer software que reconhe\u00e7a arquivos GeoTIFF atrav\u00e9s de um arquivo CSV de \u00edndice dos dados do Landsat. Sentinel-2 API: constela\u00e7\u00e3o de dois sat\u00e9lites de observa\u00e7\u00e3o da Terra SEUS Os dados s\u00e3o ideais para aplicativos de agricultura, silvicultura e outros tipos de administra\u00e7\u00e3o de terra. esse conjunto de dados est\u00e1 dispon\u00edvel gratuitamente no programa Google Public Cloud Data. Geo Server: servidor de c\u00f3digo aberto escrito em Java que permite aos usu\u00e1rios compartilhar, processar e editar dados geoespaciais. Projetado para interoperabilidade, publica dados de qualquer fonte de dados espaciais importantes usando padr\u00f5es abertos. PostgreSQL: sistema de gerenciamento de banco de dados objeto-relacional (SGBDOR) baseado no POSTGRES Vers\u00e3o 4.2. Spring Boot: facilitar o processo de configura\u00e7\u00e3o e publica\u00e7\u00e3o de aplica\u00e7\u00f5es. Pode-se escolher os m\u00f3dulos que precisa atrav\u00e9s dos starters que inclui no pom.xml do projeto. Basicamente, s\u00e3o depend\u00eancias que agrupam outras depend\u00eancias. Angular: estrutura de design de aplicativo e plataforma de desenvolvimento para criar aplicativos de p\u00e1gina \u00fanica eficientes e sofisticados. Java: linguagem de programa\u00e7\u00e3o orientada a objetos que \u00e9 amplamente usada para o desenvolvimento de sites e aplicativos. Permite o desenvolvimento de programas multiplataforma, que podem ser executados em qualquer dispositivo. Python: linguagem de programa\u00e7\u00e3o de alto n\u00edvel, interpretada, de script, imperativa, orientada a objetos, funcional, de tipagem din\u00e2mica e forte, para a implementa\u00e7\u00e3o da inteligencia artificial. Conda Environment: gerenciador de ambientes virtuais para a linguagem python. Mkdocs: gerador de documenta\u00e7\u00e3o baseado na linguagem python. Github: Sistema de controle de vers\u00e3o distribuido e gerenciamento de c\u00f3digo-fonte, fornece controle de acesso e v\u00e1rios recursos de colabora\u00e7\u00e3o, como rastreamento de erros, solicita\u00e7\u00f5es de recursos, gerenciamento de tarefas e wikis para cada projeto. Microsoft TEAM: Trata-se de um aplicativo de bate-papo em grupo que permite o gerenciamento de diversas conversas em um \u00fanico ambiente de controle. Foi desenvolvido para facilitar a comunica\u00e7\u00e3o e promover a colabora\u00e7\u00e3o entre as equipes da empresa/projeto.","title":"Implementa\u00e7\u00e3o"},{"location":"api-restful/","text":"API Spring Boot RESTful \u00b6 Projeto Integrador entre o sexto per\u00edodo da Faculdade de Tecnologia de S\u00e3o Jos\u00e9 dos Campos, Professor Jessen Vidal de An\u00e1lise e Desenvolvimento de Sistemas e a empresa Visiona , para qual nos forneceu o problema da identifica\u00e7\u00e3o de talh\u00f5es em imagens de sensoriamento remoto. Para o funcionamento da API Spring Boot com o cat\u00e1logo de imagens, \u00e9 necess\u00e1rio os seguintes requisitos: Uma inst\u00e2ncia do banco de dados PostgreSQL/PostGIS em execu\u00e7\u00e3o e configurado; Um servidor de mapas Geoserver em execu\u00e7\u00e3o e configurado; Projeto \u00b6 Este projeto consiste em: Desenvolvimento de uma API RESTful para o cat\u00e1logo de imagens georreferenciados em um banco de dados PostGIS; Com dados multitemporais, utilizar-se de intelig\u00eancia artificial para identificar talh\u00f5es em uma \u00e1rea de interesse. Ferramentas \u00b6 CI \u00c9 necess\u00e1rio uma m\u00e1quina virtual, esta servir\u00e1 para o software Jenkins que executar\u00e1 os processos de Integra\u00e7\u00e3o Cont\u00ednua. Se a m\u00e1quina for local, utilize o ngrok, um servi\u00e7o gratuito de tunelamento sem configura\u00e7\u00e3o de firewall ou port forwarding. Agora no Jenkins deve-se configurar a pipeline de testes nos seguintes passos: Clone : Para buscar o reposit\u00f3rio com os novos dados; Environment : Instala as depend\u00eancias do projeto; Testes : Execu\u00e7\u00e3o dos Testes JUnit. Configuar Webhook no GitHUB para o endpoint do Jenkins ( URL do ngrok se foi utilizado ) e ativar a op\u00e7\u00e3o: * GitHub hook trigger for GITScm polling CD a definir processo de deploy. Instala\u00e7\u00e3o e execu\u00e7\u00e3o da aplica\u00e7\u00e3o \u00b6 Instala\u00e7\u00e3o para o ambiente de desenvolvimento \u00b6 Obs.: Necess\u00e1rio instala\u00e7\u00e3o do gradle 5+ . $ gradle bootRun Execu\u00e7\u00e3o da aplica\u00e7\u00e3o em micro servi\u00e7os \u00b6 Obs.: N\u00e3o esque\u00e7a de mudar o endere\u00e7o IP (localhost) do banco de dados no arquivo application.properties para o endere\u00e7o real do servidor PostgreSQL do seu computador. ## Gerar o arquivo execut\u00e1vel `.jar` utilizando o Gradle 5 $ gradle build ## Construir a imagem docker com base no `Dockerfile` $ docker build -t spring-restful . ## Executar o container localmente $ docker run --name spring-api-restful -p 4040:8080 -d spring-restful O banco de dados criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es: Ap\u00f3s o comando docker run digite o seguinte docker ps para listar os servi\u00e7os em execu\u00e7\u00e3o pelo seu docker instalado, a resposta deve ser a seguinte: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a06cb1ccf107 spring-restful \"java -jar /app.jar\" 25 hours ago Up 25 hours 0 .0.0.0:4040->8080/tcp spring-api-restful Em seu navegador digite o seguinte link localhost:8080/catalog/list . Opera\u00e7\u00f5es \u00b6 Listagem: lista todas as imagens cadastradas no banco de dados Postgre por m\u00e9todo GET: GET localhost:8080/catalog/list [ { \"id\" : 1 , \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"id\" : 1 , \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 , \"catalog\" : null }, { \"id\" : 2 , \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 , \"catalog\" : null } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } ] Cadastro de imagens: cadastra uma imagem com os atributos definidos nos exemplos no banco de dados Postgre por m\u00e9todo POST: POST localhost:8080/catalog/add { \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 }, { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } Busca de imagens: busca imagens a partir de uma dado pol\u00edgono formatado em GeoJSON com os atributos definidos nos exemplos em proje\u00e7\u00e3o EPSG:4326 com banco de dados Postgre por m\u00e9todo POST: POST localhost:8080/catalog/search { \"dateTime\" : \"2017-06-12 08:35:46\" , \"band\" : \"VV\" , \"geojson\" : { \"type\" : \"FeatureCollection\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : {}, \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ [ -47.3016357421875 , -11.248449735768247 ], ... ] ] } } ] } } Obs.: Voc\u00ea pode aprender mais sobre GeoJSON's com o geojson.io . Refer\u00eancias \u00b6 Visiona ; Jenkins ; ngrok ;","title":"About"},{"location":"api-restful/#api-spring-boot-restful","text":"Projeto Integrador entre o sexto per\u00edodo da Faculdade de Tecnologia de S\u00e3o Jos\u00e9 dos Campos, Professor Jessen Vidal de An\u00e1lise e Desenvolvimento de Sistemas e a empresa Visiona , para qual nos forneceu o problema da identifica\u00e7\u00e3o de talh\u00f5es em imagens de sensoriamento remoto. Para o funcionamento da API Spring Boot com o cat\u00e1logo de imagens, \u00e9 necess\u00e1rio os seguintes requisitos: Uma inst\u00e2ncia do banco de dados PostgreSQL/PostGIS em execu\u00e7\u00e3o e configurado; Um servidor de mapas Geoserver em execu\u00e7\u00e3o e configurado;","title":"API Spring Boot RESTful"},{"location":"api-restful/#projeto","text":"Este projeto consiste em: Desenvolvimento de uma API RESTful para o cat\u00e1logo de imagens georreferenciados em um banco de dados PostGIS; Com dados multitemporais, utilizar-se de intelig\u00eancia artificial para identificar talh\u00f5es em uma \u00e1rea de interesse.","title":"Projeto"},{"location":"api-restful/#ferramentas","text":"CI \u00c9 necess\u00e1rio uma m\u00e1quina virtual, esta servir\u00e1 para o software Jenkins que executar\u00e1 os processos de Integra\u00e7\u00e3o Cont\u00ednua. Se a m\u00e1quina for local, utilize o ngrok, um servi\u00e7o gratuito de tunelamento sem configura\u00e7\u00e3o de firewall ou port forwarding. Agora no Jenkins deve-se configurar a pipeline de testes nos seguintes passos: Clone : Para buscar o reposit\u00f3rio com os novos dados; Environment : Instala as depend\u00eancias do projeto; Testes : Execu\u00e7\u00e3o dos Testes JUnit. Configuar Webhook no GitHUB para o endpoint do Jenkins ( URL do ngrok se foi utilizado ) e ativar a op\u00e7\u00e3o: * GitHub hook trigger for GITScm polling CD a definir processo de deploy.","title":"Ferramentas"},{"location":"api-restful/#instalacao-e-execucao-da-aplicacao","text":"","title":"Instala\u00e7\u00e3o e execu\u00e7\u00e3o da aplica\u00e7\u00e3o"},{"location":"api-restful/#instalacao-para-o-ambiente-de-desenvolvimento","text":"Obs.: Necess\u00e1rio instala\u00e7\u00e3o do gradle 5+ . $ gradle bootRun","title":"Instala\u00e7\u00e3o para o ambiente de desenvolvimento"},{"location":"api-restful/#execucao-da-aplicacao-em-micro-servicos","text":"Obs.: N\u00e3o esque\u00e7a de mudar o endere\u00e7o IP (localhost) do banco de dados no arquivo application.properties para o endere\u00e7o real do servidor PostgreSQL do seu computador. ## Gerar o arquivo execut\u00e1vel `.jar` utilizando o Gradle 5 $ gradle build ## Construir a imagem docker com base no `Dockerfile` $ docker build -t spring-restful . ## Executar o container localmente $ docker run --name spring-api-restful -p 4040:8080 -d spring-restful O banco de dados criado por essa aplica\u00e7\u00e3o possui o seguinte modelo de rela\u00e7\u00f5es: Ap\u00f3s o comando docker run digite o seguinte docker ps para listar os servi\u00e7os em execu\u00e7\u00e3o pelo seu docker instalado, a resposta deve ser a seguinte: $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a06cb1ccf107 spring-restful \"java -jar /app.jar\" 25 hours ago Up 25 hours 0 .0.0.0:4040->8080/tcp spring-api-restful Em seu navegador digite o seguinte link localhost:8080/catalog/list .","title":"Execu\u00e7\u00e3o da aplica\u00e7\u00e3o em micro servi\u00e7os"},{"location":"api-restful/#operacoes","text":"Listagem: lista todas as imagens cadastradas no banco de dados Postgre por m\u00e9todo GET: GET localhost:8080/catalog/list [ { \"id\" : 1 , \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"id\" : 1 , \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 , \"catalog\" : null }, { \"id\" : 2 , \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 , \"catalog\" : null } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } ] Cadastro de imagens: cadastra uma imagem com os atributos definidos nos exemplos no banco de dados Postgre por m\u00e9todo POST: POST localhost:8080/catalog/add { \"name\" : \"clip_20170612T083546_Sigma0_VH_db\" , \"description\" : \"sentinel A image clip_Sigma0_VH_db.tif INPE\" , \"band\" : \"VH\" , \"dateTime\" : \"2017-06-12 08:35:46\" , \"coordinates\" : [ { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.042006714207925 , \"longitude\" : -45.8734130859375 }, { \"projection\" : \"EPSG:4326\" , \"latitude\" : -12.224602049269444 , \"longitude\" : -45.7415771484375 } ], \"image\" : \"http://www.dpi.inpe.br/agricultural-database/lem/dados/cenas/Sentinel1/20170612_S1A/clip_20170612T083546_Sigma0_VH_db.tif\" } Busca de imagens: busca imagens a partir de uma dado pol\u00edgono formatado em GeoJSON com os atributos definidos nos exemplos em proje\u00e7\u00e3o EPSG:4326 com banco de dados Postgre por m\u00e9todo POST: POST localhost:8080/catalog/search { \"dateTime\" : \"2017-06-12 08:35:46\" , \"band\" : \"VV\" , \"geojson\" : { \"type\" : \"FeatureCollection\" , \"features\" : [ { \"type\" : \"Feature\" , \"properties\" : {}, \"geometry\" : { \"type\" : \"Polygon\" , \"coordinates\" : [[ [ -47.3016357421875 , -11.248449735768247 ], ... ] ] } } ] } } Obs.: Voc\u00ea pode aprender mais sobre GeoJSON's com o geojson.io .","title":"Opera\u00e7\u00f5es"},{"location":"api-restful/#referencias","text":"Visiona ; Jenkins ; ngrok ;","title":"Refer\u00eancias"},{"location":"api-restful/db/","text":"API Spring Boot PostgreSQL \u00b6 Scripts em PSQL para criar as tabelas de fei\u00e7\u00f5es para as buscas de \u00e1reas de interesse para o Sistema Web de visualiza\u00e7\u00e3o com migra\u00e7\u00e3o de dados para um banco PostgreSQL e executar em um container docker. Assim como a configura\u00e7\u00e3o do ambiente de desenvolvimento utilizando o gerenciador de container Docker com amplo uso da extens\u00e3o Postgis para o processamento de opera\u00e7\u00f5es geogr\u00e1ficas. Cria\u00e7\u00e3o do container docker PostgreSQL \u00b6 ## Download do reposit\u00f3rio oficial $ docker pull mdillon/postgis ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do Postgresql $ docker run --name postgresql -p 5480:5432 -e POSTGRES_PASSWORD=postgres -d mdillon/postgis Container docker database \u00b6 Cria\u00e7\u00e3o do container docker PGAdmin4 (Interface Gr\u00e1fica) ## Download do reposit\u00f3rio oficial $ docker pull dpage/pgadmin4 ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do PGAdmin $ docker run --name pgadmin4 -p 16543:80 -e PGADMIN_DEFAULT_EMAIL,PGADMIN_DEFAULT_PASSWORD=abner.anjos@fatec.sp.gov.br,postgres -d dpage/pgadmin4 Cria\u00e7\u00e3o do container docker PostgreSQL e PGAdmin4 (Interface Gr\u00e1fica) por default com o Docker Compose $ docker-compose up -d postgresql pgadmin4 Obs.: Ser\u00e1 necess\u00e1rio instalar a ferramenta (docker-compose)[https://docs.docker.com/compose/] e n\u00e3o esque\u00e7a de cadastrar o servidor de banco de dados PostgreSQL para o uso da interface gr\u00e1fica PGAdmin4 com as credenciais necess\u00e1rias Ambiente PSQL \u00b6 ## Instala\u00e7\u00e3o do ambiente psql CLI interface da linha de comando $ sudo apt install postgresql Migra\u00e7\u00e3o dos dados \u00b6 ## Cria\u00e7\u00e3o do banco de dados para a migra\u00e7\u00e3o $ createdb -h 0.0.0.0 -p 5480 -U postgres shapes \"Camada de fei\u00e7\u00f5es para a defini\u00e7\u00e3o de talh\u00f5es\" ## Alterando as permiss\u00f5es (exemplo) $ sudo chmod 777 -R ../db ## Cria\u00e7\u00e3o do usuario Postgres para a API e migra\u00e7\u00e3o dos dados em csv $ psql -h 0.0.0.0 -p 5480 -U postgres -d shapes -f create-tables.sql Gerenciamento do Banco de dados \u00b6 ## Entrar no banco de dados digitar a senha cadastrada para entrar $ psql -h 0.0.0.0 -p 5480 -U api_restful -d shapes ## Verificar se as tabelas e a extens\u00e3o foram criadas shapes=> SELECT table_name FROM information_schema.tables WHERE table_schema='public'; table_name ------------------- raster_columns raster_overviews municipios geography_columns geometry_columns spatial_ref_sys (6 rows) Ap\u00f3s a instala\u00e7\u00e3o do ambiente de desenvolvimento em seu navegador acesse o pgAdmin4 com o endere\u00e7o 16543 . Obs.: Colocar as credenciais do arquivo docker-compose.yml configuradas acima.","title":"Data Base"},{"location":"api-restful/db/#api-spring-boot-postgresql","text":"Scripts em PSQL para criar as tabelas de fei\u00e7\u00f5es para as buscas de \u00e1reas de interesse para o Sistema Web de visualiza\u00e7\u00e3o com migra\u00e7\u00e3o de dados para um banco PostgreSQL e executar em um container docker. Assim como a configura\u00e7\u00e3o do ambiente de desenvolvimento utilizando o gerenciador de container Docker com amplo uso da extens\u00e3o Postgis para o processamento de opera\u00e7\u00f5es geogr\u00e1ficas.","title":"API Spring Boot PostgreSQL"},{"location":"api-restful/db/#criacao-do-container-docker-postgresql","text":"## Download do reposit\u00f3rio oficial $ docker pull mdillon/postgis ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do Postgresql $ docker run --name postgresql -p 5480:5432 -e POSTGRES_PASSWORD=postgres -d mdillon/postgis","title":"Cria\u00e7\u00e3o do container docker PostgreSQL"},{"location":"api-restful/db/#container-docker-database","text":"Cria\u00e7\u00e3o do container docker PGAdmin4 (Interface Gr\u00e1fica) ## Download do reposit\u00f3rio oficial $ docker pull dpage/pgadmin4 ## Execu\u00e7\u00e3o do container com uma inst\u00e2ncia do PGAdmin $ docker run --name pgadmin4 -p 16543:80 -e PGADMIN_DEFAULT_EMAIL,PGADMIN_DEFAULT_PASSWORD=abner.anjos@fatec.sp.gov.br,postgres -d dpage/pgadmin4 Cria\u00e7\u00e3o do container docker PostgreSQL e PGAdmin4 (Interface Gr\u00e1fica) por default com o Docker Compose $ docker-compose up -d postgresql pgadmin4 Obs.: Ser\u00e1 necess\u00e1rio instalar a ferramenta (docker-compose)[https://docs.docker.com/compose/] e n\u00e3o esque\u00e7a de cadastrar o servidor de banco de dados PostgreSQL para o uso da interface gr\u00e1fica PGAdmin4 com as credenciais necess\u00e1rias","title":"Container docker database"},{"location":"api-restful/db/#ambiente-psql","text":"## Instala\u00e7\u00e3o do ambiente psql CLI interface da linha de comando $ sudo apt install postgresql","title":"Ambiente PSQL"},{"location":"api-restful/db/#migracao-dos-dados","text":"## Cria\u00e7\u00e3o do banco de dados para a migra\u00e7\u00e3o $ createdb -h 0.0.0.0 -p 5480 -U postgres shapes \"Camada de fei\u00e7\u00f5es para a defini\u00e7\u00e3o de talh\u00f5es\" ## Alterando as permiss\u00f5es (exemplo) $ sudo chmod 777 -R ../db ## Cria\u00e7\u00e3o do usuario Postgres para a API e migra\u00e7\u00e3o dos dados em csv $ psql -h 0.0.0.0 -p 5480 -U postgres -d shapes -f create-tables.sql","title":"Migra\u00e7\u00e3o dos dados"},{"location":"api-restful/db/#gerenciamento-do-banco-de-dados","text":"## Entrar no banco de dados digitar a senha cadastrada para entrar $ psql -h 0.0.0.0 -p 5480 -U api_restful -d shapes ## Verificar se as tabelas e a extens\u00e3o foram criadas shapes=> SELECT table_name FROM information_schema.tables WHERE table_schema='public'; table_name ------------------- raster_columns raster_overviews municipios geography_columns geometry_columns spatial_ref_sys (6 rows) Ap\u00f3s a instala\u00e7\u00e3o do ambiente de desenvolvimento em seu navegador acesse o pgAdmin4 com o endere\u00e7o 16543 . Obs.: Colocar as credenciais do arquivo docker-compose.yml configuradas acima.","title":"Gerenciamento do Banco de dados"},{"location":"api-restful/geoserver/","text":"Configura\u00e7\u00e3o inicial do Servidor de mapas Geoserver \u00b6 Configura\u00e7\u00e3o inicial do servidor de mapas geoserver para a postagem de camadas a serem consumidas pelo Sistema Web de visualiza\u00e7\u00e3o e identifica\u00e7\u00e3o de Talh\u00f5es proposto pelo projeto integrador Aqui neste arquivo a prioridade e a estrutura de microsservi\u00e7os, portanto vamos priorizar a instala\u00e7\u00e3o por meio da ferramenta de gerenciamento de container Docker. Montagem do ambiente de desenvolvimento \u00b6 ## Download da imagem $ docker pull kartoza/geoserver ## execu\u00e7\u00e3o do container Docker $ docker run -d -p 8686:8080 --name geoserver -e STABLE_EXTENSIONS=charts-plugin,db2-plugin kartoza/geoserver Postagem das camadas \u00b6 ## Camadas necess\u00e1rias para a execu\u00e7\u00e3o TODO Verificar se o sistema encontra em execu\u00e7\u00e3o no endere\u00e7o localhost:8686/geoserver e a p\u00e1gina de administra\u00e7\u00e3o do geoserver dever\u00e1 ser exibida. A credencial padr\u00e3o do GeoServer \u00e9 a seguinte: - Usu\u00e1rio: admin - Senha: geoserver","title":"Geoserver"},{"location":"api-restful/geoserver/#configuracao-inicial-do-servidor-de-mapas-geoserver","text":"Configura\u00e7\u00e3o inicial do servidor de mapas geoserver para a postagem de camadas a serem consumidas pelo Sistema Web de visualiza\u00e7\u00e3o e identifica\u00e7\u00e3o de Talh\u00f5es proposto pelo projeto integrador Aqui neste arquivo a prioridade e a estrutura de microsservi\u00e7os, portanto vamos priorizar a instala\u00e7\u00e3o por meio da ferramenta de gerenciamento de container Docker.","title":"Configura\u00e7\u00e3o inicial do Servidor de mapas Geoserver"},{"location":"api-restful/geoserver/#montagem-do-ambiente-de-desenvolvimento","text":"## Download da imagem $ docker pull kartoza/geoserver ## execu\u00e7\u00e3o do container Docker $ docker run -d -p 8686:8080 --name geoserver -e STABLE_EXTENSIONS=charts-plugin,db2-plugin kartoza/geoserver","title":"Montagem do ambiente de desenvolvimento"},{"location":"api-restful/geoserver/#postagem-das-camadas","text":"## Camadas necess\u00e1rias para a execu\u00e7\u00e3o TODO Verificar se o sistema encontra em execu\u00e7\u00e3o no endere\u00e7o localhost:8686/geoserver e a p\u00e1gina de administra\u00e7\u00e3o do geoserver dever\u00e1 ser exibida. A credencial padr\u00e3o do GeoServer \u00e9 a seguinte: - Usu\u00e1rio: admin - Senha: geoserver","title":"Postagem das camadas"},{"location":"changes/","text":"Sprint 1 (2020 - 03 - 20) \u00b6 Descri\u00e7\u00e3o: Entrega da defini\u00e7\u00e3o da base de dados a ser utilizada pelo sistema inteligente como cat\u00e1logo de imagens; Adapta\u00e7\u00e3o do Sistema de visualiza\u00e7\u00e3o Web GIS com a configura\u00e7\u00e3o necess\u00e1ria para a visualiza\u00e7\u00e3o dos dados geogr\u00e1ficos; Implementa\u00e7\u00e3o do Open Layers e a estrutura\u00e7\u00e3o do template. Links para as milestones e issues relacionadas \u00e0 primeira entrega (Sprint 1): API Resful - entreg\u00e1vel para a primeira sprint relacionado a API Restful, um interm\u00e9dio para a base de dados constru\u00edda e o sistema Web GIS; Sistema Web GIS - entreg\u00e1vel para a primeira sprint relacionado ao Sistema Web GIS para visualiza\u00e7\u00e3o dos dados de teste; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Declara\u00e7\u00e3o de escopo Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Design Thinking Empreendedorismo Canvas Sprint 2 (2020 - 05 - 15) \u00b6 Descri\u00e7\u00e3o: Entrega da primeira vers\u00e3o do sistema inteligente com a avalia\u00e7\u00e3o dos dados e primeiro processamento de imagens com o cat\u00e1logo de imagens do Sentinel-1; Habilita\u00e7\u00e3o do recorte de pol\u00edgonos no Sistema de visualiza\u00e7\u00e3o; Estrutura\u00e7\u00e3o do projeto completo em micro servi\u00e7os; Documenta\u00e7\u00e3o da instala\u00e7\u00e3o das demais depend\u00eancias como banco de dados PostgreSQL e servidor de mapas Geoserver, criando servi\u00e7os em Docker de forma a facilitar o desenvolvimento. Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Resful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o de Projetos Diagrama de Tempo e Custo MS Project Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Equipes Gr\u00e1fico de Burndown Sprint 3 (2020 - 05 - 29) \u00b6 Descri\u00e7\u00e3o: Cria\u00e7\u00e3o da base de dados para os os testes envolvendo o modelo criado com o TensorFlow classificador de imagens usando imagens do Sentinel e Landsat; Entrega da API Restful com a busca com pol\u00edgonos formatados em geojson verificando o recorte de imagens feito pelo Sistema Web GIS, verificando se naquele pol\u00edgono existe alguma imagem cadastrada no banco de dados geogr\u00e1fico; Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o do modelo inicial para os testes com uma base de dados m\u00ednima; API Resful - implementando buscas com GeoJSON's para uma API otimizada; Tabela de entregas: Disciplina Entrega de Documentos TODO TODO","title":"Docs"},{"location":"changes/#sprint-1-2020-03-20","text":"Descri\u00e7\u00e3o: Entrega da defini\u00e7\u00e3o da base de dados a ser utilizada pelo sistema inteligente como cat\u00e1logo de imagens; Adapta\u00e7\u00e3o do Sistema de visualiza\u00e7\u00e3o Web GIS com a configura\u00e7\u00e3o necess\u00e1ria para a visualiza\u00e7\u00e3o dos dados geogr\u00e1ficos; Implementa\u00e7\u00e3o do Open Layers e a estrutura\u00e7\u00e3o do template. Links para as milestones e issues relacionadas \u00e0 primeira entrega (Sprint 1): API Resful - entreg\u00e1vel para a primeira sprint relacionado a API Restful, um interm\u00e9dio para a base de dados constru\u00edda e o sistema Web GIS; Sistema Web GIS - entreg\u00e1vel para a primeira sprint relacionado ao Sistema Web GIS para visualiza\u00e7\u00e3o dos dados de teste; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o de Projetos Termo de Abertura de Projeto Gest\u00e3o de Projetos Diagrama de Tempo e Custo Gest\u00e3o de Projetos Declara\u00e7\u00e3o de escopo Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o Design Thinking Empreendedorismo Canvas","title":"Sprint 1 (2020 - 03 - 20)"},{"location":"changes/#sprint-2-2020-05-15","text":"Descri\u00e7\u00e3o: Entrega da primeira vers\u00e3o do sistema inteligente com a avalia\u00e7\u00e3o dos dados e primeiro processamento de imagens com o cat\u00e1logo de imagens do Sentinel-1; Habilita\u00e7\u00e3o do recorte de pol\u00edgonos no Sistema de visualiza\u00e7\u00e3o; Estrutura\u00e7\u00e3o do projeto completo em micro servi\u00e7os; Documenta\u00e7\u00e3o da instala\u00e7\u00e3o das demais depend\u00eancias como banco de dados PostgreSQL e servidor de mapas Geoserver, criando servi\u00e7os em Docker de forma a facilitar o desenvolvimento. Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o da base de dados a ser consumida; API Resful - interm\u00e9dio para a base de dados e o sistema Web GIS; Sistema Web GIS - visualiza\u00e7\u00e3o do resultado final; Tabela de entregas: Disciplina Entrega de Documentos Gest\u00e3o e Governan\u00e7a de Tecnologia da Informa\u00e7\u00e3o BSC - Balanced Scorecard Gest\u00e3o de Projetos Diagrama de Tempo e Custo MS Project Gest\u00e3o de Projetos Vis\u00e3o Geral do Custo de Recursos Gest\u00e3o de Equipes Gr\u00e1fico de Burndown","title":"Sprint 2 (2020 - 05 - 15)"},{"location":"changes/#sprint-3-2020-05-29","text":"Descri\u00e7\u00e3o: Cria\u00e7\u00e3o da base de dados para os os testes envolvendo o modelo criado com o TensorFlow classificador de imagens usando imagens do Sentinel e Landsat; Entrega da API Restful com a busca com pol\u00edgonos formatados em geojson verificando o recorte de imagens feito pelo Sistema Web GIS, verificando se naquele pol\u00edgono existe alguma imagem cadastrada no banco de dados geogr\u00e1fico; Links para as milestones e issues relacionadas \u00e0 segunda entrega (Sprint 2): Sistema Inteligente - constru\u00e7\u00e3o do modelo inicial para os testes com uma base de dados m\u00ednima; API Resful - implementando buscas com GeoJSON's para uma API otimizada; Tabela de entregas: Disciplina Entrega de Documentos TODO TODO","title":"Sprint 3 (2020 - 05 - 29)"},{"location":"python-cnn/","text":"Python Convolutional Neural Networks \u00b6 O sistema deve reconhecer \u00e1reas de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade) em um mapa, utilizando dados multitemporais, atrav\u00e9s de intelig\u00eancia artificial, a interface gr\u00e1fica (Web GIS), deve permitir ao usu\u00e1rio selecionar um intervalo de tempo e as imagens de um cat\u00e1logo dispon\u00edvel para a regi\u00e3o selecionada, carregando-as em bloco para n\u00e3o sobrecarregar o sistema e ter op\u00e7\u00e3o para download. Web GIS (Web Geographic Information System): Portal de um \u201cSistema de Informa\u00e7\u00e3o Geogr\u00e1fica\u201d (SIG), baseado em padr\u00e3o de servi\u00e7os web OGC, fornecendo uma estrutura para visualiza\u00e7\u00e3o e navega\u00e7\u00e3o de mapas (basemaps) e de dados geogr\u00e1ficos vetoriais e matriciais. Cat\u00e1logo de Imagem: O Cat\u00e1logo de Imagem deve possibilitar a cataloga\u00e7\u00e3o de cole\u00e7\u00f5es de dados espa\u00e7o-temporal, (metadados) dos sat\u00e9lites Landsat 8 e Sentinel-2. Obs: O cat\u00e1logo de imagem tamb\u00e9m dever\u00e1 fornecer interface (web API) que permitir\u00e1 consultar e recuperar as cenas de sat\u00e9lite catalogadas. Esta interface possibilitar\u00e1 que o Web GIS realize pesquisas complexas, filtrando diferentes par\u00e2metros e especificando crit\u00e9rios geogr\u00e1ficos. Map Tile Engine: Esse componente deve produzir \u201cmap raster tile\u201d para uma determinada cena de sat\u00e9lite, obedecendo ao padr\u00e3o OGC WMTS. Permitindo que usu\u00e1rios do Web GIS visualizem e naveguem pelas imagens sem precisar baix\u00e1-las (real time streaming). Cada map tile \u00e9 uma representa\u00e7\u00e3o visual de parte da imagem, n\u00e3o dos dados em si. Esses tiles geralmente s\u00e3o renderizados em formato pict\u00f3rico (PNG ou JPEG) que podem ser exibidos em uma aplica\u00e7\u00e3o web. Download: Ap\u00f3s a consulta \u00e0s imagens de uma determinada \u00e1rea de interesse, o sistema permite o download de todas as cenas (com todas as suas bandas) do per\u00edodo selecionado pelo usu\u00e1rio (Pilha de imagem). M\u00e1scara (Mask): Neste m\u00f3dulo, o sistema gerar\u00e1 uma m\u00e1scara bin\u00e1ria com as regi\u00f5es de interesse (AOI\u2019s) para cada cena selecionada. A constru\u00e7\u00e3o das m\u00e1scaras de sa\u00edda das \u00e1reas de interesse, se d\u00e3o apresentando valor igual a um (1) dentro desse poligono, enquanto as demais \u00e1reas (\u00e1reas n\u00e3o selecionadas) apresentam valor igual a zero (0). Arquivo: Ap\u00f3s a gera\u00e7\u00e3o da m\u00e1scara para cada cena (scene), \u00e9 preciso armazen\u00e1-la tanto para valida\u00e7\u00e3o visual quanto para download. Com isso, nesse m\u00f3dulo a m\u00e1scara deve ser armazenada de alguma forma que possibilite ao usu\u00e1rio fazer sua valida\u00e7\u00e3o visual (pr\u00f3xima etapa), assim como o download para treinamento de modelos de intelig\u00eancia artificial. Funcionamento das redes neurais convolucionais para o processamento das imagens. Obs.: Instala\u00e7\u00e3o do Miniconda \u00e9 necess\u00e1ria para a execu\u00e7\u00e3o dos comandos a seguir. Ambiente de Desenvolvimento \u00b6 # Montar no ambiente Linux $ sudo apt-get update $ sudo apt-get install python-numpy gdal-bin libgdal-dev # Crie um novo ambiente conda com Python3+ $ conda create --name python-cnn python=3.6.9 # Ativar o ambiente $ conda activate python-cnn # Com o ambiente ativado instalar o ipykernel (python-cnn) $ conda install notebook ipykernel # Com o ipykernel criar um kernel com o python 3.5 autom\u00e1tico (python-cnn) $ ipython kernel install --user --name python-cnn # Instalar o servidor Jupyter Lab (python-cnn) $ python -m pip install jupyter # Instalar a biblioteca gdal e basemap para processar as imagens (python-cnn) $ conda install -c conda-forge gdal=2.4.4 decartes # Executar o servidor em modo de desenvolvimento (python-cnn) $ jupyter notebook Obs.: Pode ser que o Notebook n\u00e3o reconhe\u00e7a o kernel instalado pelo conda, sendo assim voc\u00ea pode alterar manualmente kernel >> Change Kernel >> python-cnn . Ambiente de micro servi\u00e7os em docker \u00b6 # Construir a imagem Docker $ docker build -t jupyter-python-cnn . # Executar a imagem $ docker run --name jupyter-python-cnn-docker -p 8890:8888 -d jupyter-python-cnn C\u00f3digo fonte \u00b6 Tamb\u00e9m ser\u00e1 necess\u00e1rio acesso ao servidores FTP: Sentinel-1 Data ; Sentinel-2 Data ; Landsat-8 Data ; Para a execu\u00e7\u00e3o do c\u00f3digo fonte abaixo \u00e9 necess\u00e1rio o download da pasta data/ , ap\u00f3s o download descompacte na pasta root do projeto. data/ |_ input/ |_ train/ |_ false/ |_ true/ |_ validation/ |_ br_uf/ |_ false/ |_ LEM_shapes/ |_ true/ |_ output/ # !pip install tensorflow numpy matplotlib pillow wget rasterio geopandas import os import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense , Conv2D , Flatten , Dropout , MaxPooling2D from tensorflow.keras.preprocessing.image import ImageDataGenerator import numpy as np import matplotlib.pyplot as plt # Abstra\u00e7\u00e3o das buscas por pol\u00edgonos e georasters from services.georasters import Georaster from services.vector import Vector data = Georaster ( '2017-06-12 08h:35m:46s' , 'vh' , 4326 ) data . openRemoteFile () True data . projection 'EPSG:4326' data . downloadRemoteFile () True data . convertFileToJPG () True data . georaster . read ( 1 ) array([[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], dtype=float32) data . jpg for coords in data . geom . get ( 'coordinates' ): for coord in coords : print ( data . georaster . read ( 1 )[ int ( coord [ 1 ])][ int ( coord [ 0 ])]) -18.735785 -19.409836 -20.503849 -17.980326 -18.735785 shapes = Vector ( 4326 ) data . geom data_geom = shapes . shape ( data . geom . get ( 'coordinates' )[ 0 ]) data_geom data . geom {'type': 'Polygon', 'coordinates': [[[-46.422421, -11.831513], [-46.426524, -12.598503], [-45.629512, -12.601568], [-45.627701, -11.834385], [-46.422421, -11.831513]]]} shapes . lem . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NM_MUNICIP CD_GEOCMU geometry 0 LU\u00c3\u008dS EDUARDO MAGALH\u00c3\u0083ES 2919553 POLYGON ((-45.71038 -12.39706, -45.71422 -12.3... shapes . covers . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id area_ha Jun_2017 Jul_2017 Aug_2017 Sep_2017 Oct_2017 Nov_2017 Dec_2017 Jan_2018 Feb_2018 Mar_2018 Apr_2018 May_2018 Jun_2018 Geral variacao var geometry 0 1 341.632515 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((391870.392 8678209.011, 390327.395 8... 1 523 148.290258 millet millet uncultivated soil uncultivated soil uncultivated soil not identified uncultivated soil not identified not identified uncultivated soil millet millet uncultivated soil llxxx-x--xllx lxlx ll POLYGON ((362953.448 8648254.537, 362492.885 8... 2 3 196.784309 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((394667.970 8677930.309, 394381.632 8... 3 524 28.625248 sorghum sorghum sorghum uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil zzzxxxxsssxxx zxsx zs POLYGON ((378784.772 8650768.854, 378340.528 8... 4 6 369.452478 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxxssxxx xsx s POLYGON ((398795.097 8680743.662, 398796.144 8... shapes . lem . plot ( color = 'black' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7ff1c3878358> shapes . covers . plot ( color = 'white' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7ff135251be0> ! ls - l data / input / train / true total 1696536 -rw-r--r-- 1 abner abner 117589085 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 58825766 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 228341788 mai 14 11:18 image1.tif -rw-rw-r-- 1 abner abner 231710599 mai 27 07:59 image2.tif -rw-r--r-- 1 abner abner 228918854 mai 11 17:15 image3.tif -rw-rw-r-- 1 abner abner 231557786 mai 11 10:27 image4.tif -rw-rw-r-- 1 abner abner 228275958 mai 11 10:27 image5.tif -rw-r--r-- 1 abner abner 117743705 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743683 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 58903076 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589063 jun 4 2018 image9.tif for i in range ( 11 ): if data . convertAnyFileToJPG ( \"data/input/train/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 ! ls - l data / input / train / false total 1608788 -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image12.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image13.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image14.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image1.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image2.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image3.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image4.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image5.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image9.tif for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/train/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 Converted Image 12 Converted Image 13 Converted Image 14 ! ls - Rl data / input / train data/input/train: total 1130016 -rw-r--r-- 1 abner abner 8298184 mai 15 14:37 clip_20170612T083546_Sigma0_VH_db.jpg -rw-r--r-- 1 abner abner 228341788 mai 14 11:18 clip_20170612T083546_Sigma0_VH_db.tif -rw-rw-r-- 1 abner abner 231710599 mai 27 07:59 clip_20170612T083546_Sigma0_VV_db.tif -rw-rw-r-- 1 abner abner 228275958 mai 11 10:27 clip_20170624T083547_Sigma0_VH_db.tif -rw-rw-r-- 1 abner abner 231557786 mai 11 10:27 clip_20170624T083547_Sigma0_VV_db.tif -rw-r--r-- 1 abner abner 228918854 mai 11 17:15 clip_20180315T083548_Sigma0_VH_db.tif drwxr-xr-x 2 abner abner 4096 mai 27 11:31 false drwxr-xr-x 2 abner abner 4096 mai 27 11:28 true data/input/train/false: total 856928 -rw-r--r-- 1 abner abner 835637688 mai 27 11:30 geotifs.zip -rw-r--r-- 1 abner abner 41848673 mai 27 11:31 jpgs.zip data/input/train/true: total 1168760 -rw-r--r-- 1 abner abner 1151611114 mai 27 11:27 geotifs.zip -rw-r--r-- 1 abner abner 45190244 mai 27 11:28 jpgs.zip ! ls - l data / input / validation / true total 2020720 -rw-rw-r-- 1 abner abner 230180639 mai 27 15:27 image1.tif -rw-rw-r-- 1 abner abner 233288867 mai 27 15:27 image2.tif -rw-rw-r-- 1 abner abner 230717127 mai 27 15:24 image3.tif -rw-rw-r-- 1 abner abner 233672094 mai 27 15:25 image4.tif -rw-rw-r-- 1 abner abner 228496143 mai 27 15:19 image5.tif -rw-rw-r-- 1 abner abner 226850973 mai 27 15:21 image6.tif -rw-rw-r-- 1 abner abner 229910342 mai 27 15:21 image7.tif -rw-rw-r-- 1 abner abner 229693774 mai 27 15:23 image8.tif -rw-rw-r-- 1 abner abner 226351595 mai 27 15:23 image9.tif for i in range ( 9 ): if data . convertAnyFileToJPG ( \"data/input/validation/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 ! ls - l data / input / validation / false total 1608772 -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image12.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image13.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image14.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image1.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image2.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image3.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image4.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image5.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image9.tif for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/validation/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 Converted Image 12 Converted Image 13 Converted Image 14 PATH = \"data/input\" PATH 'data/input' train_dir = os . path . join ( PATH , 'train' ) validation_dir = os . path . join ( PATH , 'validation' ) train_false_dir = os . path . join ( train_dir , 'false' ) train_true_dir = os . path . join ( train_dir , 'true' ) validation_false_dir = os . path . join ( validation_dir , 'false' ) validation_true_dir = os . path . join ( validation_dir , 'true' ) num_false_tr = len ( os . listdir ( train_false_dir )) num_true_tr = len ( os . listdir ( train_true_dir )) num_false_val = len ( os . listdir ( validation_false_dir )) num_true_val = len ( os . listdir ( validation_true_dir )) total_train = num_false_tr + num_true_tr total_val = num_false_val + num_true_val print ( 'total training false images:' , num_false_tr ) print ( 'total training true images:' , num_true_tr ) print ( 'total validation false images:' , num_false_val ) print ( 'total validation true images:' , num_true_val ) print ( \"--\" ) print ( \"Total training images:\" , total_train ) print ( \"Total validation images:\" , total_val ) total training false images: 28 total training true images: 22 total validation false images: 42 total validation true images: 18 -- Total training images: 50 Total validation images: 60 batch_size = 10 epochs = 5 IMG_HEIGHT = 150 IMG_WIDTH = 150 train_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) # Generator for our training data validation_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) # Generator for our validation data train_data_gen = train_image_generator . flow_from_directory ( batch_size = batch_size , directory = train_dir , shuffle = True , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 50 images belonging to 2 classes. val_data_gen = validation_image_generator . flow_from_directory ( batch_size = batch_size , directory = validation_dir , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 46 images belonging to 4 classes. sample_training_images , _ = next ( train_data_gen ) # This function will plot images in the form of # a grid with 1 row and 5 columns where images are placed in each column. def plotImages ( images_arr ): fig , axes = plt . subplots ( 1 , 5 , figsize = ( 20 , 20 )) axes = axes . flatten () for img , ax in zip ( images_arr , axes ): ax . imshow ( img ) ax . axis ( 'off' ) plt . tight_layout () plt . show () plotImages ( sample_training_images [: 5 ]) model = Sequential ([ Conv2D ( 16 , 3 , padding = 'same' , activation = 'relu' , input_shape = ( IMG_HEIGHT , IMG_WIDTH , 3 )), MaxPooling2D (), Conv2D ( 32 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 1 ) ]) model . compile ( optimizer = 'adam' , loss = tf . keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ 'accuracy' ] ) model . summary () Model: \"sequential_1\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 150, 150, 16) 448 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 75, 75, 16) 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, 75, 75, 32) 4640 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 37, 37, 32) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 37, 37, 64) 18496 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 18, 18, 64) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 20736) 0 _________________________________________________________________ dense_2 (Dense) (None, 512) 10617344 _________________________________________________________________ dense_3 (Dense) (None, 1) 513 ================================================================= Total params: 10,641,441 Trainable params: 10,641,441 Non-trainable params: 0 _________________________________________________________________ history = model . fit_generator ( train_data_gen , steps_per_epoch = total_train // batch_size , epochs = epochs , validation_data = val_data_gen , validation_steps = total_val // batch_size ) Epoch 1/5 5/5 [==============================] - 988s 198s/step - loss: 1.5733 - accuracy: 0.4960 - val_loss: 3.9526 - val_accuracy: 0.0000e+00 Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f95b8569710>> Traceback (most recent call last): File \"/home/abner/miniconda3/envs/neural-networks/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 538, in __del__ handle=self._handle, deleter=self._deleter) File \"/home/abner/miniconda3/envs/neural-networks/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1139, in delete_iterator tld.op_callbacks, handle, deleter) KeyboardInterrupt: Epoch 2/5 4/5 [=======================>......] - ETA: 56s - loss: 0.7279 - accuracy: 0.5850","title":"Sistema Inteligente"},{"location":"python-cnn/#python-convolutional-neural-networks","text":"O sistema deve reconhecer \u00e1reas de talh\u00f5es (unidade m\u00ednima de cultivo de uma propriedade) em um mapa, utilizando dados multitemporais, atrav\u00e9s de intelig\u00eancia artificial, a interface gr\u00e1fica (Web GIS), deve permitir ao usu\u00e1rio selecionar um intervalo de tempo e as imagens de um cat\u00e1logo dispon\u00edvel para a regi\u00e3o selecionada, carregando-as em bloco para n\u00e3o sobrecarregar o sistema e ter op\u00e7\u00e3o para download. Web GIS (Web Geographic Information System): Portal de um \u201cSistema de Informa\u00e7\u00e3o Geogr\u00e1fica\u201d (SIG), baseado em padr\u00e3o de servi\u00e7os web OGC, fornecendo uma estrutura para visualiza\u00e7\u00e3o e navega\u00e7\u00e3o de mapas (basemaps) e de dados geogr\u00e1ficos vetoriais e matriciais. Cat\u00e1logo de Imagem: O Cat\u00e1logo de Imagem deve possibilitar a cataloga\u00e7\u00e3o de cole\u00e7\u00f5es de dados espa\u00e7o-temporal, (metadados) dos sat\u00e9lites Landsat 8 e Sentinel-2. Obs: O cat\u00e1logo de imagem tamb\u00e9m dever\u00e1 fornecer interface (web API) que permitir\u00e1 consultar e recuperar as cenas de sat\u00e9lite catalogadas. Esta interface possibilitar\u00e1 que o Web GIS realize pesquisas complexas, filtrando diferentes par\u00e2metros e especificando crit\u00e9rios geogr\u00e1ficos. Map Tile Engine: Esse componente deve produzir \u201cmap raster tile\u201d para uma determinada cena de sat\u00e9lite, obedecendo ao padr\u00e3o OGC WMTS. Permitindo que usu\u00e1rios do Web GIS visualizem e naveguem pelas imagens sem precisar baix\u00e1-las (real time streaming). Cada map tile \u00e9 uma representa\u00e7\u00e3o visual de parte da imagem, n\u00e3o dos dados em si. Esses tiles geralmente s\u00e3o renderizados em formato pict\u00f3rico (PNG ou JPEG) que podem ser exibidos em uma aplica\u00e7\u00e3o web. Download: Ap\u00f3s a consulta \u00e0s imagens de uma determinada \u00e1rea de interesse, o sistema permite o download de todas as cenas (com todas as suas bandas) do per\u00edodo selecionado pelo usu\u00e1rio (Pilha de imagem). M\u00e1scara (Mask): Neste m\u00f3dulo, o sistema gerar\u00e1 uma m\u00e1scara bin\u00e1ria com as regi\u00f5es de interesse (AOI\u2019s) para cada cena selecionada. A constru\u00e7\u00e3o das m\u00e1scaras de sa\u00edda das \u00e1reas de interesse, se d\u00e3o apresentando valor igual a um (1) dentro desse poligono, enquanto as demais \u00e1reas (\u00e1reas n\u00e3o selecionadas) apresentam valor igual a zero (0). Arquivo: Ap\u00f3s a gera\u00e7\u00e3o da m\u00e1scara para cada cena (scene), \u00e9 preciso armazen\u00e1-la tanto para valida\u00e7\u00e3o visual quanto para download. Com isso, nesse m\u00f3dulo a m\u00e1scara deve ser armazenada de alguma forma que possibilite ao usu\u00e1rio fazer sua valida\u00e7\u00e3o visual (pr\u00f3xima etapa), assim como o download para treinamento de modelos de intelig\u00eancia artificial. Funcionamento das redes neurais convolucionais para o processamento das imagens. Obs.: Instala\u00e7\u00e3o do Miniconda \u00e9 necess\u00e1ria para a execu\u00e7\u00e3o dos comandos a seguir.","title":"Python Convolutional Neural Networks"},{"location":"python-cnn/#ambiente-de-desenvolvimento","text":"# Montar no ambiente Linux $ sudo apt-get update $ sudo apt-get install python-numpy gdal-bin libgdal-dev # Crie um novo ambiente conda com Python3+ $ conda create --name python-cnn python=3.6.9 # Ativar o ambiente $ conda activate python-cnn # Com o ambiente ativado instalar o ipykernel (python-cnn) $ conda install notebook ipykernel # Com o ipykernel criar um kernel com o python 3.5 autom\u00e1tico (python-cnn) $ ipython kernel install --user --name python-cnn # Instalar o servidor Jupyter Lab (python-cnn) $ python -m pip install jupyter # Instalar a biblioteca gdal e basemap para processar as imagens (python-cnn) $ conda install -c conda-forge gdal=2.4.4 decartes # Executar o servidor em modo de desenvolvimento (python-cnn) $ jupyter notebook Obs.: Pode ser que o Notebook n\u00e3o reconhe\u00e7a o kernel instalado pelo conda, sendo assim voc\u00ea pode alterar manualmente kernel >> Change Kernel >> python-cnn .","title":"Ambiente de Desenvolvimento"},{"location":"python-cnn/#ambiente-de-micro-servicos-em-docker","text":"# Construir a imagem Docker $ docker build -t jupyter-python-cnn . # Executar a imagem $ docker run --name jupyter-python-cnn-docker -p 8890:8888 -d jupyter-python-cnn","title":"Ambiente de micro servi\u00e7os em docker"},{"location":"python-cnn/#codigo-fonte","text":"Tamb\u00e9m ser\u00e1 necess\u00e1rio acesso ao servidores FTP: Sentinel-1 Data ; Sentinel-2 Data ; Landsat-8 Data ; Para a execu\u00e7\u00e3o do c\u00f3digo fonte abaixo \u00e9 necess\u00e1rio o download da pasta data/ , ap\u00f3s o download descompacte na pasta root do projeto. data/ |_ input/ |_ train/ |_ false/ |_ true/ |_ validation/ |_ br_uf/ |_ false/ |_ LEM_shapes/ |_ true/ |_ output/ # !pip install tensorflow numpy matplotlib pillow wget rasterio geopandas import os import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense , Conv2D , Flatten , Dropout , MaxPooling2D from tensorflow.keras.preprocessing.image import ImageDataGenerator import numpy as np import matplotlib.pyplot as plt # Abstra\u00e7\u00e3o das buscas por pol\u00edgonos e georasters from services.georasters import Georaster from services.vector import Vector data = Georaster ( '2017-06-12 08h:35m:46s' , 'vh' , 4326 ) data . openRemoteFile () True data . projection 'EPSG:4326' data . downloadRemoteFile () True data . convertFileToJPG () True data . georaster . read ( 1 ) array([[nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], ..., [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan], [nan, nan, nan, ..., nan, nan, nan]], dtype=float32) data . jpg for coords in data . geom . get ( 'coordinates' ): for coord in coords : print ( data . georaster . read ( 1 )[ int ( coord [ 1 ])][ int ( coord [ 0 ])]) -18.735785 -19.409836 -20.503849 -17.980326 -18.735785 shapes = Vector ( 4326 ) data . geom data_geom = shapes . shape ( data . geom . get ( 'coordinates' )[ 0 ]) data_geom data . geom {'type': 'Polygon', 'coordinates': [[[-46.422421, -11.831513], [-46.426524, -12.598503], [-45.629512, -12.601568], [-45.627701, -11.834385], [-46.422421, -11.831513]]]} shapes . lem . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } NM_MUNICIP CD_GEOCMU geometry 0 LU\u00c3\u008dS EDUARDO MAGALH\u00c3\u0083ES 2919553 POLYGON ((-45.71038 -12.39706, -45.71422 -12.3... shapes . covers . head ( 5 ) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Id area_ha Jun_2017 Jul_2017 Aug_2017 Sep_2017 Oct_2017 Nov_2017 Dec_2017 Jan_2018 Feb_2018 Mar_2018 Apr_2018 May_2018 Jun_2018 Geral variacao var geometry 0 1 341.632515 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((391870.392 8678209.011, 390327.395 8... 1 523 148.290258 millet millet uncultivated soil uncultivated soil uncultivated soil not identified uncultivated soil not identified not identified uncultivated soil millet millet uncultivated soil llxxx-x--xllx lxlx ll POLYGON ((362953.448 8648254.537, 362492.885 8... 2 3 196.784309 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxsssxxx xsx s POLYGON ((394667.970 8677930.309, 394381.632 8... 3 524 28.625248 sorghum sorghum sorghum uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean soybean uncultivated soil uncultivated soil uncultivated soil zzzxxxxsssxxx zxsx zs POLYGON ((378784.772 8650768.854, 378340.528 8... 4 6 369.452478 uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil uncultivated soil soybean soybean uncultivated soil uncultivated soil uncultivated soil xxxxxxxxssxxx xsx s POLYGON ((398795.097 8680743.662, 398796.144 8... shapes . lem . plot ( color = 'black' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7ff1c3878358> shapes . covers . plot ( color = 'white' , edgecolor = 'black' , figsize = ( 8 , 8 )) <matplotlib.axes._subplots.AxesSubplot at 0x7ff135251be0> ! ls - l data / input / train / true total 1696536 -rw-r--r-- 1 abner abner 117589085 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 58825766 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 228341788 mai 14 11:18 image1.tif -rw-rw-r-- 1 abner abner 231710599 mai 27 07:59 image2.tif -rw-r--r-- 1 abner abner 228918854 mai 11 17:15 image3.tif -rw-rw-r-- 1 abner abner 231557786 mai 11 10:27 image4.tif -rw-rw-r-- 1 abner abner 228275958 mai 11 10:27 image5.tif -rw-r--r-- 1 abner abner 117743705 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743683 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 58903076 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589063 jun 4 2018 image9.tif for i in range ( 11 ): if data . convertAnyFileToJPG ( \"data/input/train/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 ! ls - l data / input / train / false total 1608788 -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image12.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image13.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image14.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image1.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image2.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image3.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image4.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image5.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image9.tif for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/train/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 Converted Image 12 Converted Image 13 Converted Image 14 ! ls - Rl data / input / train data/input/train: total 1130016 -rw-r--r-- 1 abner abner 8298184 mai 15 14:37 clip_20170612T083546_Sigma0_VH_db.jpg -rw-r--r-- 1 abner abner 228341788 mai 14 11:18 clip_20170612T083546_Sigma0_VH_db.tif -rw-rw-r-- 1 abner abner 231710599 mai 27 07:59 clip_20170612T083546_Sigma0_VV_db.tif -rw-rw-r-- 1 abner abner 228275958 mai 11 10:27 clip_20170624T083547_Sigma0_VH_db.tif -rw-rw-r-- 1 abner abner 231557786 mai 11 10:27 clip_20170624T083547_Sigma0_VV_db.tif -rw-r--r-- 1 abner abner 228918854 mai 11 17:15 clip_20180315T083548_Sigma0_VH_db.tif drwxr-xr-x 2 abner abner 4096 mai 27 11:31 false drwxr-xr-x 2 abner abner 4096 mai 27 11:28 true data/input/train/false: total 856928 -rw-r--r-- 1 abner abner 835637688 mai 27 11:30 geotifs.zip -rw-r--r-- 1 abner abner 41848673 mai 27 11:31 jpgs.zip data/input/train/true: total 1168760 -rw-r--r-- 1 abner abner 1151611114 mai 27 11:27 geotifs.zip -rw-r--r-- 1 abner abner 45190244 mai 27 11:28 jpgs.zip ! ls - l data / input / validation / true total 2020720 -rw-rw-r-- 1 abner abner 230180639 mai 27 15:27 image1.tif -rw-rw-r-- 1 abner abner 233288867 mai 27 15:27 image2.tif -rw-rw-r-- 1 abner abner 230717127 mai 27 15:24 image3.tif -rw-rw-r-- 1 abner abner 233672094 mai 27 15:25 image4.tif -rw-rw-r-- 1 abner abner 228496143 mai 27 15:19 image5.tif -rw-rw-r-- 1 abner abner 226850973 mai 27 15:21 image6.tif -rw-rw-r-- 1 abner abner 229910342 mai 27 15:21 image7.tif -rw-rw-r-- 1 abner abner 229693774 mai 27 15:23 image8.tif -rw-rw-r-- 1 abner abner 226351595 mai 27 15:23 image9.tif for i in range ( 9 ): if data . convertAnyFileToJPG ( \"data/input/validation/true/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 ! ls - l data / input / validation / false total 1608772 -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image10.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image11.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image12.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image13.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image14.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image1.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image2.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image3.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image4.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image5.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image6.tif -rw-r--r-- 1 abner abner 117743711 jun 4 2018 image7.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image8.tif -rw-r--r-- 1 abner abner 117589091 jun 4 2018 image9.tif for i in range ( 14 ): if data . convertAnyFileToJPG ( \"data/input/validation/false/image {} \" . format ( i + 1 )): print ( \"Converted Image {} \" . format ( i + 1 )) Converted Image 1 Converted Image 2 Converted Image 3 Converted Image 4 Converted Image 5 Converted Image 6 Converted Image 7 Converted Image 8 Converted Image 9 Converted Image 10 Converted Image 11 Converted Image 12 Converted Image 13 Converted Image 14 PATH = \"data/input\" PATH 'data/input' train_dir = os . path . join ( PATH , 'train' ) validation_dir = os . path . join ( PATH , 'validation' ) train_false_dir = os . path . join ( train_dir , 'false' ) train_true_dir = os . path . join ( train_dir , 'true' ) validation_false_dir = os . path . join ( validation_dir , 'false' ) validation_true_dir = os . path . join ( validation_dir , 'true' ) num_false_tr = len ( os . listdir ( train_false_dir )) num_true_tr = len ( os . listdir ( train_true_dir )) num_false_val = len ( os . listdir ( validation_false_dir )) num_true_val = len ( os . listdir ( validation_true_dir )) total_train = num_false_tr + num_true_tr total_val = num_false_val + num_true_val print ( 'total training false images:' , num_false_tr ) print ( 'total training true images:' , num_true_tr ) print ( 'total validation false images:' , num_false_val ) print ( 'total validation true images:' , num_true_val ) print ( \"--\" ) print ( \"Total training images:\" , total_train ) print ( \"Total validation images:\" , total_val ) total training false images: 28 total training true images: 22 total validation false images: 42 total validation true images: 18 -- Total training images: 50 Total validation images: 60 batch_size = 10 epochs = 5 IMG_HEIGHT = 150 IMG_WIDTH = 150 train_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) # Generator for our training data validation_image_generator = ImageDataGenerator ( rescale = 1. / 255 ) # Generator for our validation data train_data_gen = train_image_generator . flow_from_directory ( batch_size = batch_size , directory = train_dir , shuffle = True , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 50 images belonging to 2 classes. val_data_gen = validation_image_generator . flow_from_directory ( batch_size = batch_size , directory = validation_dir , target_size = ( IMG_HEIGHT , IMG_WIDTH ), class_mode = 'binary' ) Found 46 images belonging to 4 classes. sample_training_images , _ = next ( train_data_gen ) # This function will plot images in the form of # a grid with 1 row and 5 columns where images are placed in each column. def plotImages ( images_arr ): fig , axes = plt . subplots ( 1 , 5 , figsize = ( 20 , 20 )) axes = axes . flatten () for img , ax in zip ( images_arr , axes ): ax . imshow ( img ) ax . axis ( 'off' ) plt . tight_layout () plt . show () plotImages ( sample_training_images [: 5 ]) model = Sequential ([ Conv2D ( 16 , 3 , padding = 'same' , activation = 'relu' , input_shape = ( IMG_HEIGHT , IMG_WIDTH , 3 )), MaxPooling2D (), Conv2D ( 32 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' ), MaxPooling2D (), Flatten (), Dense ( 512 , activation = 'relu' ), Dense ( 1 ) ]) model . compile ( optimizer = 'adam' , loss = tf . keras . losses . BinaryCrossentropy ( from_logits = True ), metrics = [ 'accuracy' ] ) model . summary () Model: \"sequential_1\" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_3 (Conv2D) (None, 150, 150, 16) 448 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 75, 75, 16) 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, 75, 75, 32) 4640 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 37, 37, 32) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 37, 37, 64) 18496 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 18, 18, 64) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 20736) 0 _________________________________________________________________ dense_2 (Dense) (None, 512) 10617344 _________________________________________________________________ dense_3 (Dense) (None, 1) 513 ================================================================= Total params: 10,641,441 Trainable params: 10,641,441 Non-trainable params: 0 _________________________________________________________________ history = model . fit_generator ( train_data_gen , steps_per_epoch = total_train // batch_size , epochs = epochs , validation_data = val_data_gen , validation_steps = total_val // batch_size ) Epoch 1/5 5/5 [==============================] - 988s 198s/step - loss: 1.5733 - accuracy: 0.4960 - val_loss: 3.9526 - val_accuracy: 0.0000e+00 Exception ignored in: <bound method IteratorResourceDeleter.__del__ of <tensorflow.python.data.ops.iterator_ops.IteratorResourceDeleter object at 0x7f95b8569710>> Traceback (most recent call last): File \"/home/abner/miniconda3/envs/neural-networks/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 538, in __del__ handle=self._handle, deleter=self._deleter) File \"/home/abner/miniconda3/envs/neural-networks/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1139, in delete_iterator tld.op_callbacks, handle, deleter) KeyboardInterrupt: Epoch 2/5 4/5 [=======================>......] - ETA: 56s - loss: 0.7279 - accuracy: 0.5850","title":"C\u00f3digo fonte"},{"location":"web-gis/","text":"Web GIS \u00b6 Sistema Web GIS para a visualiza\u00e7\u00e3o de talh\u00f5es com dados espa\u00e7o-temporais, permitindo o recorte e buscas de \u00e1reas de interesse por extensivo uso da biblioteca Openlayers . Para a execu\u00e7\u00e3o desta aplica\u00e7\u00e3o ao \u00e9 necess\u00e1rio ter o projeto API Restful em execu\u00e7\u00e3o utilizando Docker ou o ambiente de desenvolvimento. Execu\u00e7\u00e3o para o ambiente de micro servi\u00e7os em Docker \u00b6 Obs.: Necess\u00e1ria instala\u00e7\u00e3o do Node 10+ e Angular CLI 9+ , n\u00e3o esque\u00e7a de modificar o ip do servi\u00e7o de cache em app/services/cache-system.ts . ## Construir o pacote HTML para a execu\u00e7\u00e3o do http-server $ ng build ## Copie o arquivo Dockerfile para o pacote rec\u00e9m-gerado $ cp Dockerfile dist/web-gis && cd dist/web-gis Para a execu\u00e7\u00e3o do ambiente em docker execute os seguintes comandos: ## Crie uma imagem para a execu\u00e7\u00e3o do container $ docker build -t web-gis:latest . ## Fica a criterio do usuario criar um volume para armazenar os dados $ docker container run --name app-smh-ui -p 8082:8080 -d web-gis:latest Abaixo se encontra a aplica\u00e7\u00e3o em funcionamento utilizando os passos anteriores: Este projeto foi gerado utilizando Angular CLI vers\u00e3o 9+. Servidor para o ambiente de desenvolvimento \u00b6 Executar o seguinte comando ng serve para executar um novo servidor de desenvolvimento. No navegador procure pelo endere\u00e7o http://localhost:4200/ . A aplica\u00e7\u00e3o ir\u00e1 realizar a leitura autom\u00e1tica de arquivos em conjunto com as altera\u00e7\u00f5es implementadas. Desenvolvimento de c\u00f3digo \u00b6 Executar o seguinte comando ng generate component component-name para gerar um novo componente em Linguagem TypeScript . Gerando pacotes HTML \u00b6 Execute o seguinte comando ng build para gerar o pacote HTML para a execu\u00e7\u00e3o. Use o comando --prod tag para o ambiente de produ\u00e7\u00e3o. Testes Unit\u00e1rios \u00b6 Execute ng test para executar os testes unit\u00e1rios via Karma . Executando testes end-to-end \u00b6 Execute ng e2e para executar o testes end-to-end via Protractor Ajuda FAQ \u00b6 Para maisinforma\u00e7\u00f5es sobre a usabilidade da interface de linha de comando use ng help ou d\u00ea uma olhada Angular CLI README .","title":"Web-GIS"},{"location":"web-gis/#web-gis","text":"Sistema Web GIS para a visualiza\u00e7\u00e3o de talh\u00f5es com dados espa\u00e7o-temporais, permitindo o recorte e buscas de \u00e1reas de interesse por extensivo uso da biblioteca Openlayers . Para a execu\u00e7\u00e3o desta aplica\u00e7\u00e3o ao \u00e9 necess\u00e1rio ter o projeto API Restful em execu\u00e7\u00e3o utilizando Docker ou o ambiente de desenvolvimento.","title":"Web GIS"},{"location":"web-gis/#execucao-para-o-ambiente-de-micro-servicos-em-docker","text":"Obs.: Necess\u00e1ria instala\u00e7\u00e3o do Node 10+ e Angular CLI 9+ , n\u00e3o esque\u00e7a de modificar o ip do servi\u00e7o de cache em app/services/cache-system.ts . ## Construir o pacote HTML para a execu\u00e7\u00e3o do http-server $ ng build ## Copie o arquivo Dockerfile para o pacote rec\u00e9m-gerado $ cp Dockerfile dist/web-gis && cd dist/web-gis Para a execu\u00e7\u00e3o do ambiente em docker execute os seguintes comandos: ## Crie uma imagem para a execu\u00e7\u00e3o do container $ docker build -t web-gis:latest . ## Fica a criterio do usuario criar um volume para armazenar os dados $ docker container run --name app-smh-ui -p 8082:8080 -d web-gis:latest Abaixo se encontra a aplica\u00e7\u00e3o em funcionamento utilizando os passos anteriores: Este projeto foi gerado utilizando Angular CLI vers\u00e3o 9+.","title":"Execu\u00e7\u00e3o para o ambiente de micro servi\u00e7os em Docker"},{"location":"web-gis/#servidor-para-o-ambiente-de-desenvolvimento","text":"Executar o seguinte comando ng serve para executar um novo servidor de desenvolvimento. No navegador procure pelo endere\u00e7o http://localhost:4200/ . A aplica\u00e7\u00e3o ir\u00e1 realizar a leitura autom\u00e1tica de arquivos em conjunto com as altera\u00e7\u00f5es implementadas.","title":"Servidor para o ambiente de desenvolvimento"},{"location":"web-gis/#desenvolvimento-de-codigo","text":"Executar o seguinte comando ng generate component component-name para gerar um novo componente em Linguagem TypeScript .","title":"Desenvolvimento de c\u00f3digo"},{"location":"web-gis/#gerando-pacotes-html","text":"Execute o seguinte comando ng build para gerar o pacote HTML para a execu\u00e7\u00e3o. Use o comando --prod tag para o ambiente de produ\u00e7\u00e3o.","title":"Gerando pacotes HTML"},{"location":"web-gis/#testes-unitarios","text":"Execute ng test para executar os testes unit\u00e1rios via Karma .","title":"Testes Unit\u00e1rios"},{"location":"web-gis/#executando-testes-end-to-end","text":"Execute ng e2e para executar o testes end-to-end via Protractor","title":"Executando testes end-to-end"},{"location":"web-gis/#ajuda-faq","text":"Para maisinforma\u00e7\u00f5es sobre a usabilidade da interface de linha de comando use ng help ou d\u00ea uma olhada Angular CLI README .","title":"Ajuda FAQ"}]}